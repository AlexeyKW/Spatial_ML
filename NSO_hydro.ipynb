{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imsave, imread\n",
    "data_path = 'data/nso/'\n",
    "image_rows = 420\n",
    "image_cols = 580"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_path = os.path.join(data_path, 'gray/train')\n",
    "images = os.listdir(train_data_path)\n",
    "total = len(images) / 2\n",
    "imgs = np.ndarray((int(total), image_rows, image_cols), dtype=np.uint8)\n",
    "imgs_mask = np.ndarray((int(total), image_rows, image_cols), dtype=np.uint8)\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 0/1000.0 images\n",
      "Done: 100/1000.0 images\n",
      "Done: 200/1000.0 images\n",
      "Done: 300/1000.0 images\n",
      "Done: 400/1000.0 images\n",
      "Done: 500/1000.0 images\n",
      "Done: 600/1000.0 images\n",
      "Done: 700/1000.0 images\n",
      "Done: 800/1000.0 images\n",
      "Done: 900/1000.0 images\n",
      "Loading done.\n"
     ]
    }
   ],
   "source": [
    "for image_name in images:\n",
    "        if 'mask' in image_name:\n",
    "            continue\n",
    "        image_mask_name = image_name.split('.')[0] + '_mask.png'\n",
    "        img = imread(os.path.join(train_data_path, image_name), as_grey=True)\n",
    "        img_mask = imread(os.path.join(train_data_path, image_mask_name), as_grey=True)\n",
    "\n",
    "        img = np.array([img])\n",
    "        img_mask = np.array([img_mask])\n",
    "\n",
    "        imgs[i] = img\n",
    "        imgs_mask[i] = img_mask\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Done: {0}/{1} images'.format(i, total))\n",
    "        i += 1\n",
    "print('Loading done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to .npy files done.\n"
     ]
    }
   ],
   "source": [
    "np.save(data_path+'imgs_train.npy', imgs)\n",
    "np.save(data_path+'imgs_mask_train.npy', imgs_mask)\n",
    "print('Saving to .npy files done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_path = os.path.join(data_path, 'gray/test')\n",
    "images = os.listdir(train_data_path)\n",
    "total = len(images)\n",
    "imgs = np.ndarray((total, image_rows, image_cols), dtype=np.uint8)\n",
    "imgs_id = np.ndarray((total, ), dtype=np.int32)\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 0/274 images\n",
      "Done: 100/274 images\n",
      "Done: 200/274 images\n",
      "Loading done.\n"
     ]
    }
   ],
   "source": [
    "for image_name in images:\n",
    "        img_id = int(image_name.split('.')[0])\n",
    "        img = imread(os.path.join(train_data_path, image_name), as_grey=True)\n",
    "\n",
    "        img = np.array([img])\n",
    "\n",
    "        imgs[i] = img\n",
    "        imgs_id[i] = img_id\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Done: {0}/{1} images'.format(i, total))\n",
    "        i += 1\n",
    "print('Loading done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to .npy files done.\n"
     ]
    }
   ],
   "source": [
    "np.save(data_path+'imgs_test.npy', imgs)\n",
    "np.save(data_path+'imgs_id_test.npy', imgs_id)\n",
    "print('Saving to .npy files done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs_train = np.load(data_path+'imgs_train.npy')\n",
    "imgs_mask_train = np.load(data_path+'imgs_mask_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows = 96\n",
    "img_cols = 96\n",
    "smooth = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(imgs):\n",
    "    imgs_p = np.ndarray((imgs.shape[0], img_rows, img_cols), dtype=np.uint8)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_p[i] = resize(imgs[i], (img_cols, img_rows), preserve_range=True)\n",
    "    imgs_p = imgs_p[..., np.newaxis]\n",
    "    return imgs_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = Input((img_rows, img_cols, 1))\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "imgs_train = preprocess(imgs_train)\n",
    "imgs_mask_train = preprocess(imgs_mask_train)\n",
    "\n",
    "imgs_train = imgs_train.astype('float32')\n",
    "mean = np.mean(imgs_train)  # mean for data centering\n",
    "std = np.std(imgs_train)  # std for data normalization\n",
    "\n",
    "imgs_train -= mean\n",
    "imgs_train /= std\n",
    "\n",
    "imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "imgs_mask_train /= 255. # scale masks to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/20\n",
      "800/800 [==============================] - 144s - loss: -0.0398 - dice_coef: 0.0398 - val_loss: -0.1097 - val_dice_coef: 0.1097\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 143s - loss: -0.0403 - dice_coef: 0.0403 - val_loss: -0.1122 - val_dice_coef: 0.1122\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 142s - loss: -0.0410 - dice_coef: 0.0410 - val_loss: -0.1145 - val_dice_coef: 0.1145\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 143s - loss: -0.0419 - dice_coef: 0.0419 - val_loss: -0.1169 - val_dice_coef: 0.1169\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 142s - loss: -0.0427 - dice_coef: 0.0427 - val_loss: -0.1195 - val_dice_coef: 0.1195\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 142s - loss: -0.0431 - dice_coef: 0.0431 - val_loss: -0.1246 - val_dice_coef: 0.1246\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 143s - loss: -0.0463 - dice_coef: 0.0463 - val_loss: -0.1357 - val_dice_coef: 0.1357\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 142s - loss: -0.0519 - dice_coef: 0.0519 - val_loss: -0.1663 - val_dice_coef: 0.1663\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 145s - loss: -0.0625 - dice_coef: 0.0625 - val_loss: -0.2241 - val_dice_coef: 0.2241\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 154s - loss: -0.0820 - dice_coef: 0.0820 - val_loss: -0.2914 - val_dice_coef: 0.2914\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 143s - loss: -0.0898 - dice_coef: 0.0898 - val_loss: -0.3428 - val_dice_coef: 0.3428\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 142s - loss: -0.1078 - dice_coef: 0.1078 - val_loss: -0.3342 - val_dice_coef: 0.3342\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 142s - loss: -0.1182 - dice_coef: 0.1182 - val_loss: -0.4134 - val_dice_coef: 0.4134\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 142s - loss: -0.1314 - dice_coef: 0.1314 - val_loss: -0.3609 - val_dice_coef: 0.3609\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 142s - loss: -0.1400 - dice_coef: 0.1400 - val_loss: -0.4660 - val_dice_coef: 0.4660\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 143s - loss: -0.1481 - dice_coef: 0.1481 - val_loss: -0.4170 - val_dice_coef: 0.4170\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 146s - loss: -0.1651 - dice_coef: 0.1651 - val_loss: -0.4951 - val_dice_coef: 0.4951\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 144s - loss: -0.1714 - dice_coef: 0.1714 - val_loss: -0.5437 - val_dice_coef: 0.5437\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 146s - loss: -0.2193 - dice_coef: 0.2193 - val_loss: -0.5571 - val_dice_coef: 0.5571\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 144s - loss: -0.2421 - dice_coef: 0.2421 - val_loss: -0.5747 - val_dice_coef: 0.5747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x98c26533c8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "model.fit(imgs_train, imgs_mask_train, batch_size=32, nb_epoch=20, verbose=1, shuffle=True, validation_split=0.2, callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "imgs_test = np.load(data_path+'imgs_test.npy')\n",
    "imgs_test = preprocess(imgs_test)\n",
    "imgs_test = imgs_test.astype('float32')\n",
    "imgs_test -= mean\n",
    "imgs_test /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 16s    \n"
     ]
    }
   ],
   "source": [
    "imgs_mask_test = model.predict(imgs_test, verbose=1)\n",
    "np.save('imgs_mask_test.npy', imgs_mask_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs_id_test = np.load(data_path+'imgs_id_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\skimage\\io\\_io.py:132: UserWarning: data/nso/preds\\103_pred.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\skimage\\io\\_io.py:132: UserWarning: data/nso/preds\\104_pred.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\skimage\\io\\_io.py:132: UserWarning: data/nso/preds\\105_pred.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\skimage\\io\\_io.py:132: UserWarning: data/nso/preds\\106_pred.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\skimage\\io\\_io.py:132: UserWarning: data/nso/preds\\177_pred.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\skimage\\io\\_io.py:132: UserWarning: data/nso/preds\\51_pred.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\skimage\\io\\_io.py:132: UserWarning: data/nso/preds\\52_pred.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\skimage\\io\\_io.py:132: UserWarning: data/nso/preds\\85_pred.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n"
     ]
    }
   ],
   "source": [
    "pred_dir = data_path+'preds'\n",
    "if not os.path.exists(pred_dir):\n",
    "    os.mkdir(pred_dir)\n",
    "for image, image_id in zip(imgs_mask_test, imgs_id_test):\n",
    "    image = (image[:, :, 0] * 255.).astype(np.uint8)\n",
    "    imsave(os.path.join(pred_dir, str(image_id) + '_pred.png'), image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
