{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score: 28.8942"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "E:\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "E:\\Miniconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\Miniconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\Miniconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\Miniconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\Miniconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\Miniconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Bidirectional\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data_dengue/dengue_features_train.csv', index_col=None)\n",
    "df_y_train = pd.read_csv('data_dengue/dengue_labels_train.csv', index_col=None)\n",
    "X_test = pd.read_csv('data_dengue/dengue_features_test.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['week_start_date'] = pd.to_datetime(X_train['week_start_date'])\n",
    "X_train['week_start_date'] = X_train['week_start_date'] - pd.to_datetime('1980-01-01')\n",
    "X_train['week_start_date'] = pd.to_numeric(X_train['week_start_date'])/100000000000\n",
    "X_train_new = X_train.fillna(X_train.mean())\n",
    "X_train_sj=X_train_new[X_train_new.city=='sj']\n",
    "X_train_iq=X_train_new[X_train_new.city=='iq']\n",
    "X_train_sj = X_train_sj.drop(['city'], axis=1)\n",
    "X_train_iq = X_train_iq.drop(['city'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['week_start_date'] = pd.to_datetime(X_test['week_start_date'])\n",
    "X_test['week_start_date'] = X_test['week_start_date'] - pd.to_datetime('1980-01-01')\n",
    "X_test['week_start_date'] = pd.to_numeric(X_test['week_start_date'])/100000000000\n",
    "X_test_new = X_test.fillna(X_test.mean())\n",
    "X_test_sj=X_test_new[X_test_new.city=='sj']\n",
    "X_test_iq=X_test_new[X_test_new.city=='iq']\n",
    "X_test_sj = X_test_sj.drop(['city'], axis=1)\n",
    "X_test_iq = X_test_iq.drop(['city'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sj_float = X_train_sj.astype('float64')\n",
    "X_train_iq_float = X_train_iq.astype('float64')\n",
    "X_test_sj_float = X_test_sj.astype('float64')\n",
    "X_test_iq_float = X_test_iq.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_sj_scaled = min_max_scaler.fit_transform(X_train_sj_float)\n",
    "X_train_iq_scaled = min_max_scaler.fit_transform(X_train_iq_float)\n",
    "X_test_sj_scaled = min_max_scaler.transform(X_test_sj_float)\n",
    "X_test_iq_scaled = min_max_scaler.transform(X_test_iq_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.32692308 0.         0.58783972 0.62676332 0.52370092\n",
      "  0.54188858 0.03179724 0.26100844 0.26918536 0.33993342 0.30769231\n",
      "  0.45205479 0.05609115 0.3181382  0.03179724 0.29739227 0.35849109\n",
      "  0.35968379 0.4403183  0.30337079 0.28205128 0.05230467]\n",
      " [0.         0.34615385 0.00106594 0.64041572 0.66981079 0.43529974\n",
      "  0.49214226 0.05842294 0.36299338 0.38488784 0.5284738  0.47692308\n",
      "  0.52054795 0.0314461  0.51021387 0.05842294 0.47346033 0.28598728\n",
      "  0.53557312 0.34217507 0.56179775 0.56410256 0.02811376]\n",
      " [0.         0.36538462 0.00213187 0.48741177 0.70428426 0.42268026\n",
      "  0.52666235 0.08842806 0.45402692 0.45690673 0.7103557  0.41538462\n",
      "  0.64383562 0.04574934 0.73498766 0.08842806 0.66450897 0.26584733\n",
      "  0.53557312 0.36339523 0.61797753 0.64102564 0.13533835]\n",
      " [0.         0.38461538 0.00319781 0.59454599 0.78500526 0.59484481\n",
      "  0.67286631 0.03932412 0.48688113 0.51475797 0.69511127 0.55384615\n",
      "  0.60273973 0.02436459 0.65265972 0.03932412 0.64176068 0.30209923\n",
      "  0.64031621 0.41644562 0.74157303 0.70512821 0.01307617]\n",
      " [0.         0.40384615 0.00426374 0.66964931 0.80418719 0.65269924\n",
      "  0.69861342 0.01925243 0.57175451 0.58677686 0.75784125 0.63076923\n",
      "  0.67123288 0.02138475 0.65855498 0.01925243 0.71130017 0.46724682\n",
      "  0.84387352 0.89920424 0.93258427 0.78205128 0.01896044]]\n",
      "(936, 23)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_sj_scaled[:5, :])\n",
    "print(X_train_sj_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1s_sj = X_train_sj_scaled.reshape(X_train_sj_scaled.shape[0],1,X_train_sj_scaled.shape[1])\n",
    "train_1s_iq = X_train_iq_scaled.reshape(X_train_iq_scaled.shape[0],1,X_train_iq_scaled.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(936, 1, 23)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1s_sj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(936,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y_1s_sj = np.array(df_y_train[df_y_train.city=='sj'][\"total_cases\"])\n",
    "data_y_1s_iq = np.array(df_y_train[df_y_train.city=='iq'][\"total_cases\"])\n",
    "data_y_1s_sj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1s_sj = Sequential()\n",
    "model_1s_sj.add(Bidirectional(LSTM(50, activation='relu', return_sequences=True, input_shape=(1, 23))))\n",
    "model_1s_sj.add(Bidirectional(LSTM(40, activation='relu', return_sequences=True)))\n",
    "model_1s_sj.add(Bidirectional(LSTM(20, activation='relu')))\n",
    "model_1s_sj.add(Dense(1))\n",
    "model_1s_sj.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Miniconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/400\n",
      "936/936 [==============================] - 7s 7ms/step - loss: 34.1011\n",
      "Epoch 2/400\n",
      "936/936 [==============================] - 0s 408us/step - loss: 30.6186\n",
      "Epoch 3/400\n",
      "936/936 [==============================] - 0s 431us/step - loss: 25.3261\n",
      "Epoch 4/400\n",
      "936/936 [==============================] - 0s 399us/step - loss: 24.8015\n",
      "Epoch 5/400\n",
      "936/936 [==============================] - 0s 416us/step - loss: 24.3795\n",
      "Epoch 6/400\n",
      "936/936 [==============================] - 0s 424us/step - loss: 24.0856\n",
      "Epoch 7/400\n",
      "936/936 [==============================] - 0s 382us/step - loss: 24.0449\n",
      "Epoch 8/400\n",
      "936/936 [==============================] - 0s 404us/step - loss: 23.6680\n",
      "Epoch 9/400\n",
      "936/936 [==============================] - 0s 404us/step - loss: 23.4376\n",
      "Epoch 10/400\n",
      "936/936 [==============================] - 0s 413us/step - loss: 23.2761\n",
      "Epoch 11/400\n",
      "936/936 [==============================] - 0s 395us/step - loss: 23.2689\n",
      "Epoch 12/400\n",
      "936/936 [==============================] - 0s 462us/step - loss: 22.9252\n",
      "Epoch 13/400\n",
      "936/936 [==============================] - 0s 505us/step - loss: 22.8519\n",
      "Epoch 14/400\n",
      "936/936 [==============================] - 0s 432us/step - loss: 22.7097\n",
      "Epoch 15/400\n",
      "936/936 [==============================] - 0s 417us/step - loss: 22.6179\n",
      "Epoch 16/400\n",
      "936/936 [==============================] - 0s 403us/step - loss: 22.48820s - loss: 22.52\n",
      "Epoch 17/400\n",
      "936/936 [==============================] - 0s 401us/step - loss: 22.4584\n",
      "Epoch 18/400\n",
      "936/936 [==============================] - 0s 421us/step - loss: 22.1948\n",
      "Epoch 19/400\n",
      "936/936 [==============================] - 0s 403us/step - loss: 22.0990\n",
      "Epoch 20/400\n",
      "936/936 [==============================] - 0s 443us/step - loss: 22.0551\n",
      "Epoch 21/400\n",
      "936/936 [==============================] - 0s 411us/step - loss: 21.9515\n",
      "Epoch 22/400\n",
      "936/936 [==============================] - 0s 397us/step - loss: 21.8384\n",
      "Epoch 23/400\n",
      "936/936 [==============================] - 0s 393us/step - loss: 21.8064\n",
      "Epoch 24/400\n",
      "936/936 [==============================] - 0s 429us/step - loss: 21.6349\n",
      "Epoch 25/400\n",
      "936/936 [==============================] - 0s 451us/step - loss: 21.5414\n",
      "Epoch 26/400\n",
      "936/936 [==============================] - 0s 411us/step - loss: 21.6123\n",
      "Epoch 27/400\n",
      "936/936 [==============================] - 0s 398us/step - loss: 21.4390\n",
      "Epoch 28/400\n",
      "936/936 [==============================] - 0s 408us/step - loss: 21.2590\n",
      "Epoch 29/400\n",
      "936/936 [==============================] - 0s 388us/step - loss: 21.2797\n",
      "Epoch 30/400\n",
      "936/936 [==============================] - 0s 393us/step - loss: 21.1024\n",
      "Epoch 31/400\n",
      "936/936 [==============================] - 0s 405us/step - loss: 20.9968\n",
      "Epoch 32/400\n",
      "936/936 [==============================] - 0s 380us/step - loss: 20.9962\n",
      "Epoch 33/400\n",
      "936/936 [==============================] - 0s 380us/step - loss: 21.0541\n",
      "Epoch 34/400\n",
      "936/936 [==============================] - 0s 430us/step - loss: 20.8836\n",
      "Epoch 35/400\n",
      "936/936 [==============================] - 0s 412us/step - loss: 21.0629\n",
      "Epoch 36/400\n",
      "936/936 [==============================] - 0s 403us/step - loss: 20.8759\n",
      "Epoch 37/400\n",
      "936/936 [==============================] - 0s 392us/step - loss: 21.0007\n",
      "Epoch 38/400\n",
      "936/936 [==============================] - 0s 427us/step - loss: 20.8168\n",
      "Epoch 39/400\n",
      "936/936 [==============================] - 0s 414us/step - loss: 20.7593\n",
      "Epoch 40/400\n",
      "936/936 [==============================] - 0s 427us/step - loss: 20.6521\n",
      "Epoch 41/400\n",
      "936/936 [==============================] - 0s 413us/step - loss: 20.7096\n",
      "Epoch 42/400\n",
      "936/936 [==============================] - ETA: 0s - loss: 20.78 - 0s 391us/step - loss: 20.6907\n",
      "Epoch 43/400\n",
      "936/936 [==============================] - 0s 400us/step - loss: 20.5419\n",
      "Epoch 44/400\n",
      "936/936 [==============================] - 0s 389us/step - loss: 20.5660\n",
      "Epoch 45/400\n",
      "936/936 [==============================] - 0s 411us/step - loss: 20.56350s - loss: 2\n",
      "Epoch 46/400\n",
      "936/936 [==============================] - 0s 422us/step - loss: 20.6011\n",
      "Epoch 47/400\n",
      "936/936 [==============================] - 0s 412us/step - loss: 20.5749\n",
      "Epoch 48/400\n",
      "936/936 [==============================] - 0s 396us/step - loss: 20.5849\n",
      "Epoch 49/400\n",
      "936/936 [==============================] - 0s 399us/step - loss: 20.5501\n",
      "Epoch 50/400\n",
      "936/936 [==============================] - 0s 410us/step - loss: 20.4428\n",
      "Epoch 51/400\n",
      "936/936 [==============================] - 0s 453us/step - loss: 20.4978\n",
      "Epoch 52/400\n",
      "936/936 [==============================] - 0s 411us/step - loss: 20.4856\n",
      "Epoch 53/400\n",
      "936/936 [==============================] - 0s 403us/step - loss: 20.4838\n",
      "Epoch 54/400\n",
      "936/936 [==============================] - 0s 421us/step - loss: 20.4157\n",
      "Epoch 55/400\n",
      "936/936 [==============================] - 0s 407us/step - loss: 20.5654\n",
      "Epoch 56/400\n",
      "936/936 [==============================] - 0s 409us/step - loss: 20.4166\n",
      "Epoch 57/400\n",
      "936/936 [==============================] - 0s 430us/step - loss: 20.4706\n",
      "Epoch 58/400\n",
      "936/936 [==============================] - 0s 409us/step - loss: 20.3822\n",
      "Epoch 59/400\n",
      "936/936 [==============================] - 0s 410us/step - loss: 20.4247\n",
      "Epoch 60/400\n",
      "936/936 [==============================] - 0s 407us/step - loss: 20.3681\n",
      "Epoch 61/400\n",
      "936/936 [==============================] - 0s 420us/step - loss: 20.2804\n",
      "Epoch 62/400\n",
      "936/936 [==============================] - 0s 408us/step - loss: 20.3797\n",
      "Epoch 63/400\n",
      "936/936 [==============================] - 0s 422us/step - loss: 20.4288\n",
      "Epoch 64/400\n",
      "936/936 [==============================] - 0s 441us/step - loss: 20.2988\n",
      "Epoch 65/400\n",
      "936/936 [==============================] - 0s 437us/step - loss: 20.2657\n",
      "Epoch 66/400\n",
      "936/936 [==============================] - 0s 432us/step - loss: 20.2576\n",
      "Epoch 67/400\n",
      "936/936 [==============================] - 1s 817us/step - loss: 20.4609\n",
      "Epoch 68/400\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 20.3031\n",
      "Epoch 69/400\n",
      "936/936 [==============================] - 1s 551us/step - loss: 20.3552\n",
      "Epoch 70/400\n",
      "936/936 [==============================] - 0s 409us/step - loss: 20.2428\n",
      "Epoch 71/400\n",
      "936/936 [==============================] - 0s 428us/step - loss: 20.2221\n",
      "Epoch 72/400\n",
      "936/936 [==============================] - 0s 515us/step - loss: 20.2063\n",
      "Epoch 73/400\n",
      "936/936 [==============================] - 0s 421us/step - loss: 20.3458\n",
      "Epoch 74/400\n",
      "936/936 [==============================] - 0s 502us/step - loss: 20.4126\n",
      "Epoch 75/400\n",
      "936/936 [==============================] - 0s 412us/step - loss: 20.2170\n",
      "Epoch 76/400\n",
      "936/936 [==============================] - 0s 448us/step - loss: 20.1880\n",
      "Epoch 77/400\n",
      "936/936 [==============================] - 1s 537us/step - loss: 20.3965\n",
      "Epoch 78/400\n",
      "936/936 [==============================] - 0s 473us/step - loss: 20.0968\n",
      "Epoch 79/400\n",
      "936/936 [==============================] - 0s 506us/step - loss: 20.2402\n",
      "Epoch 80/400\n",
      "936/936 [==============================] - 0s 428us/step - loss: 20.1299\n",
      "Epoch 81/400\n",
      "936/936 [==============================] - 0s 429us/step - loss: 20.0830\n",
      "Epoch 82/400\n",
      "936/936 [==============================] - 0s 486us/step - loss: 20.1210\n",
      "Epoch 83/400\n",
      "936/936 [==============================] - 0s 385us/step - loss: 20.3053\n",
      "Epoch 84/400\n",
      "936/936 [==============================] - 0s 499us/step - loss: 20.1096\n",
      "Epoch 85/400\n",
      "936/936 [==============================] - 0s 532us/step - loss: 20.0873\n",
      "Epoch 86/400\n",
      "936/936 [==============================] - 0s 419us/step - loss: 20.1082\n",
      "Epoch 87/400\n",
      "936/936 [==============================] - 0s 498us/step - loss: 20.1277\n",
      "Epoch 88/400\n",
      "936/936 [==============================] - 0s 437us/step - loss: 20.5097\n",
      "Epoch 89/400\n",
      "936/936 [==============================] - 0s 533us/step - loss: 20.1528\n",
      "Epoch 90/400\n",
      "936/936 [==============================] - 0s 420us/step - loss: 20.3182\n",
      "Epoch 91/400\n",
      "936/936 [==============================] - 0s 488us/step - loss: 20.2766\n",
      "Epoch 92/400\n",
      "936/936 [==============================] - 0s 516us/step - loss: 20.0733\n",
      "Epoch 93/400\n",
      "936/936 [==============================] - 0s 448us/step - loss: 20.0319\n",
      "Epoch 94/400\n",
      "936/936 [==============================] - 0s 529us/step - loss: 20.2059\n",
      "Epoch 95/400\n",
      "936/936 [==============================] - 0s 462us/step - loss: 20.0147\n",
      "Epoch 96/400\n",
      "936/936 [==============================] - 0s 427us/step - loss: 20.0355\n",
      "Epoch 97/400\n",
      "936/936 [==============================] - 0s 482us/step - loss: 20.2956\n",
      "Epoch 98/400\n",
      "936/936 [==============================] - 0s 444us/step - loss: 19.9895\n",
      "Epoch 99/400\n",
      "936/936 [==============================] - 0s 508us/step - loss: 19.9576\n",
      "Epoch 100/400\n",
      "936/936 [==============================] - 0s 440us/step - loss: 20.1260\n",
      "Epoch 101/400\n",
      "936/936 [==============================] - 0s 505us/step - loss: 20.0794\n",
      "Epoch 102/400\n",
      "936/936 [==============================] - 1s 605us/step - loss: 19.9179\n",
      "Epoch 103/400\n",
      "936/936 [==============================] - 1s 715us/step - loss: 20.0079\n",
      "Epoch 104/400\n",
      "936/936 [==============================] - 1s 682us/step - loss: 19.8944\n",
      "Epoch 105/400\n",
      "936/936 [==============================] - 1s 805us/step - loss: 19.9831\n",
      "Epoch 106/400\n",
      "936/936 [==============================] - 1s 775us/step - loss: 19.97650s - loss: 20.09\n",
      "Epoch 107/400\n",
      "936/936 [==============================] - 1s 787us/step - loss: 20.0094\n",
      "Epoch 108/400\n",
      "936/936 [==============================] - 1s 548us/step - loss: 19.9847\n",
      "Epoch 109/400\n",
      "936/936 [==============================] - 0s 442us/step - loss: 20.0996\n",
      "Epoch 110/400\n",
      "936/936 [==============================] - 0s 480us/step - loss: 19.9635\n",
      "Epoch 111/400\n",
      "936/936 [==============================] - 0s 423us/step - loss: 19.8829\n",
      "Epoch 112/400\n",
      "936/936 [==============================] - 0s 498us/step - loss: 20.0141\n",
      "Epoch 113/400\n",
      "936/936 [==============================] - 0s 498us/step - loss: 19.8856\n",
      "Epoch 114/400\n",
      "936/936 [==============================] - 1s 640us/step - loss: 20.0133\n",
      "Epoch 115/400\n",
      "936/936 [==============================] - 0s 468us/step - loss: 19.9394\n",
      "Epoch 116/400\n",
      "936/936 [==============================] - 0s 463us/step - loss: 19.8936\n",
      "Epoch 117/400\n",
      "936/936 [==============================] - 1s 587us/step - loss: 19.9727\n",
      "Epoch 118/400\n",
      "936/936 [==============================] - 1s 613us/step - loss: 19.8240\n",
      "Epoch 119/400\n",
      "936/936 [==============================] - 0s 534us/step - loss: 19.7611\n",
      "Epoch 120/400\n",
      "936/936 [==============================] - 1s 658us/step - loss: 19.8863\n",
      "Epoch 121/400\n",
      "936/936 [==============================] - 1s 647us/step - loss: 19.8124\n",
      "Epoch 122/400\n",
      "936/936 [==============================] - 0s 425us/step - loss: 20.0191\n",
      "Epoch 123/400\n",
      "936/936 [==============================] - 0s 458us/step - loss: 19.7199\n",
      "Epoch 124/400\n",
      "936/936 [==============================] - 0s 471us/step - loss: 20.0322\n",
      "Epoch 125/400\n",
      "936/936 [==============================] - 0s 508us/step - loss: 19.8471\n",
      "Epoch 126/400\n",
      "936/936 [==============================] - 0s 502us/step - loss: 19.76790s -\n",
      "Epoch 127/400\n",
      "936/936 [==============================] - 0s 461us/step - loss: 19.8167\n",
      "Epoch 128/400\n",
      "936/936 [==============================] - 1s 867us/step - loss: 19.7964\n",
      "Epoch 129/400\n",
      "936/936 [==============================] - 1s 588us/step - loss: 19.7372\n",
      "Epoch 130/400\n",
      "936/936 [==============================] - 1s 567us/step - loss: 19.8358\n",
      "Epoch 131/400\n",
      "936/936 [==============================] - 1s 712us/step - loss: 19.7846\n",
      "Epoch 132/400\n",
      "936/936 [==============================] - 0s 478us/step - loss: 20.13910s - los\n",
      "Epoch 133/400\n",
      "936/936 [==============================] - 0s 497us/step - loss: 19.8513\n",
      "Epoch 134/400\n",
      "936/936 [==============================] - 0s 459us/step - loss: 19.6684\n",
      "Epoch 135/400\n",
      "936/936 [==============================] - 0s 467us/step - loss: 19.7034\n",
      "Epoch 136/400\n",
      "936/936 [==============================] - 0s 469us/step - loss: 19.8403\n",
      "Epoch 137/400\n",
      "936/936 [==============================] - 0s 454us/step - loss: 19.7067\n",
      "Epoch 138/400\n",
      "936/936 [==============================] - 0s 446us/step - loss: 19.9711\n",
      "Epoch 139/400\n",
      "936/936 [==============================] - 0s 469us/step - loss: 19.7719\n",
      "Epoch 140/400\n",
      "936/936 [==============================] - 0s 475us/step - loss: 19.7076\n",
      "Epoch 141/400\n",
      "936/936 [==============================] - 0s 468us/step - loss: 19.9570\n",
      "Epoch 142/400\n",
      "936/936 [==============================] - 0s 441us/step - loss: 19.71950s - loss: 19.78\n",
      "Epoch 143/400\n",
      "936/936 [==============================] - 0s 476us/step - loss: 19.6550\n",
      "Epoch 144/400\n",
      "936/936 [==============================] - 0s 500us/step - loss: 19.6613\n",
      "Epoch 145/400\n",
      "936/936 [==============================] - 0s 460us/step - loss: 19.9779\n",
      "Epoch 146/400\n",
      "936/936 [==============================] - 0s 483us/step - loss: 19.7968\n",
      "Epoch 147/400\n",
      "936/936 [==============================] - 0s 487us/step - loss: 19.7356\n",
      "Epoch 148/400\n",
      "352/936 [==========>...................] - ETA: 0s - loss: 20.5960"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Miniconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.150934). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "936/936 [==============================] - 1s 591us/step - loss: 19.6659\n",
      "Epoch 149/400\n",
      "936/936 [==============================] - 0s 358us/step - loss: 19.5003\n",
      "Epoch 150/400\n",
      "936/936 [==============================] - 0s 367us/step - loss: 19.5992\n",
      "Epoch 151/400\n",
      "936/936 [==============================] - 0s 366us/step - loss: 19.7144\n",
      "Epoch 152/400\n",
      "936/936 [==============================] - 0s 360us/step - loss: 19.5337\n",
      "Epoch 153/400\n",
      "936/936 [==============================] - 0s 377us/step - loss: 19.7453\n",
      "Epoch 154/400\n",
      "936/936 [==============================] - 0s 361us/step - loss: 19.6432\n",
      "Epoch 155/400\n",
      "936/936 [==============================] - 0s 378us/step - loss: 19.6798\n",
      "Epoch 156/400\n",
      "936/936 [==============================] - 0s 405us/step - loss: 19.7481\n",
      "Epoch 157/400\n",
      "936/936 [==============================] - 1s 542us/step - loss: 19.5738\n",
      "Epoch 158/400\n",
      "936/936 [==============================] - 0s 421us/step - loss: 19.5839\n",
      "Epoch 159/400\n",
      "936/936 [==============================] - 0s 368us/step - loss: 19.4204\n",
      "Epoch 160/400\n",
      "936/936 [==============================] - 0s 381us/step - loss: 19.8207\n",
      "Epoch 161/400\n",
      "936/936 [==============================] - 0s 388us/step - loss: 19.3455\n",
      "Epoch 162/400\n",
      "936/936 [==============================] - 0s 362us/step - loss: 19.3599\n",
      "Epoch 163/400\n",
      "936/936 [==============================] - 0s 366us/step - loss: 19.8177\n",
      "Epoch 164/400\n",
      "936/936 [==============================] - 0s 357us/step - loss: 19.3703\n",
      "Epoch 165/400\n",
      "936/936 [==============================] - 0s 356us/step - loss: 19.3609\n",
      "Epoch 166/400\n",
      "936/936 [==============================] - 0s 410us/step - loss: 19.3118\n",
      "Epoch 167/400\n",
      "936/936 [==============================] - 0s 389us/step - loss: 19.3696\n",
      "Epoch 168/400\n",
      "936/936 [==============================] - 0s 365us/step - loss: 19.3409\n",
      "Epoch 169/400\n",
      "936/936 [==============================] - 0s 361us/step - loss: 19.4419\n",
      "Epoch 170/400\n",
      "936/936 [==============================] - 0s 375us/step - loss: 19.2007\n",
      "Epoch 171/400\n",
      "936/936 [==============================] - 0s 405us/step - loss: 19.3489\n",
      "Epoch 172/400\n",
      "936/936 [==============================] - 0s 397us/step - loss: 19.4342\n",
      "Epoch 173/400\n",
      "936/936 [==============================] - 0s 383us/step - loss: 19.4267\n",
      "Epoch 174/400\n",
      "936/936 [==============================] - 0s 368us/step - loss: 19.3244\n",
      "Epoch 175/400\n",
      "936/936 [==============================] - 0s 374us/step - loss: 19.3007\n",
      "Epoch 176/400\n",
      "936/936 [==============================] - 0s 377us/step - loss: 19.2677\n",
      "Epoch 177/400\n",
      "936/936 [==============================] - 0s 365us/step - loss: 19.4017\n",
      "Epoch 178/400\n",
      "936/936 [==============================] - 0s 380us/step - loss: 19.2126\n",
      "Epoch 179/400\n",
      "936/936 [==============================] - 0s 372us/step - loss: 19.1925\n",
      "Epoch 180/400\n",
      "936/936 [==============================] - 0s 371us/step - loss: 19.1296\n",
      "Epoch 181/400\n",
      "936/936 [==============================] - 0s 376us/step - loss: 19.30350s - los\n",
      "Epoch 182/400\n",
      "936/936 [==============================] - 0s 395us/step - loss: 19.1284\n",
      "Epoch 183/400\n",
      "936/936 [==============================] - 0s 393us/step - loss: 19.1824\n",
      "Epoch 184/400\n",
      "936/936 [==============================] - 0s 383us/step - loss: 19.0532\n",
      "Epoch 185/400\n",
      "936/936 [==============================] - 0s 396us/step - loss: 18.9685\n",
      "Epoch 186/400\n",
      "936/936 [==============================] - 0s 398us/step - loss: 19.0254\n",
      "Epoch 187/400\n",
      "936/936 [==============================] - 0s 376us/step - loss: 18.9784\n",
      "Epoch 188/400\n",
      "936/936 [==============================] - 0s 361us/step - loss: 18.9338\n",
      "Epoch 189/400\n",
      "936/936 [==============================] - 0s 378us/step - loss: 19.1047\n",
      "Epoch 190/400\n",
      "936/936 [==============================] - 0s 401us/step - loss: 18.9779\n",
      "Epoch 191/400\n",
      "936/936 [==============================] - 0s 371us/step - loss: 19.7877\n",
      "Epoch 192/400\n",
      "936/936 [==============================] - 0s 407us/step - loss: 19.1511\n",
      "Epoch 193/400\n",
      "936/936 [==============================] - 0s 380us/step - loss: 19.0916\n",
      "Epoch 194/400\n",
      "936/936 [==============================] - 0s 408us/step - loss: 19.2513\n",
      "Epoch 195/400\n",
      "936/936 [==============================] - 0s 377us/step - loss: 19.2887\n",
      "Epoch 196/400\n",
      "936/936 [==============================] - 0s 388us/step - loss: 19.2040\n",
      "Epoch 197/400\n",
      "936/936 [==============================] - 0s 382us/step - loss: 19.7729\n",
      "Epoch 198/400\n",
      "936/936 [==============================] - 0s 429us/step - loss: 19.3966\n",
      "Epoch 199/400\n",
      "936/936 [==============================] - 0s 398us/step - loss: 19.0308\n",
      "Epoch 200/400\n",
      "936/936 [==============================] - 0s 425us/step - loss: 18.9688\n",
      "Epoch 201/400\n",
      "936/936 [==============================] - 0s 382us/step - loss: 19.6413\n",
      "Epoch 202/400\n",
      "936/936 [==============================] - 0s 389us/step - loss: 19.1058\n",
      "Epoch 203/400\n",
      "936/936 [==============================] - 0s 387us/step - loss: 18.9855\n",
      "Epoch 204/400\n",
      "936/936 [==============================] - 0s 367us/step - loss: 18.9690\n",
      "Epoch 205/400\n",
      "936/936 [==============================] - 0s 407us/step - loss: 19.5540\n",
      "Epoch 206/400\n",
      "936/936 [==============================] - 0s 389us/step - loss: 19.0144\n",
      "Epoch 207/400\n",
      "936/936 [==============================] - 0s 389us/step - loss: 18.9132\n",
      "Epoch 208/400\n",
      "936/936 [==============================] - 0s 403us/step - loss: 19.0797\n",
      "Epoch 209/400\n",
      "936/936 [==============================] - 0s 379us/step - loss: 18.9824\n",
      "Epoch 210/400\n",
      "936/936 [==============================] - 0s 437us/step - loss: 19.26690s - l\n",
      "Epoch 211/400\n",
      "936/936 [==============================] - 1s 621us/step - loss: 18.8072\n",
      "Epoch 212/400\n",
      "936/936 [==============================] - 0s 410us/step - loss: 18.8140\n",
      "Epoch 213/400\n",
      "936/936 [==============================] - 0s 434us/step - loss: 18.8422\n",
      "Epoch 214/400\n",
      "936/936 [==============================] - 0s 399us/step - loss: 18.8374\n",
      "Epoch 215/400\n",
      "936/936 [==============================] - 0s 411us/step - loss: 19.0407\n",
      "Epoch 216/400\n",
      "936/936 [==============================] - 0s 391us/step - loss: 19.3336\n",
      "Epoch 217/400\n",
      "936/936 [==============================] - 0s 373us/step - loss: 18.9111\n",
      "Epoch 218/400\n",
      "936/936 [==============================] - 0s 413us/step - loss: 18.9842\n",
      "Epoch 219/400\n",
      "936/936 [==============================] - 0s 404us/step - loss: 18.7332\n",
      "Epoch 220/400\n",
      "936/936 [==============================] - 0s 408us/step - loss: 18.5913\n",
      "Epoch 221/400\n",
      "936/936 [==============================] - 0s 375us/step - loss: 18.8365\n",
      "Epoch 222/400\n",
      "936/936 [==============================] - 0s 385us/step - loss: 18.7411\n",
      "Epoch 223/400\n",
      "936/936 [==============================] - 0s 376us/step - loss: 18.7552\n",
      "Epoch 224/400\n",
      "936/936 [==============================] - 0s 394us/step - loss: 18.8482\n",
      "Epoch 225/400\n",
      "936/936 [==============================] - 0s 389us/step - loss: 18.6447\n",
      "Epoch 226/400\n",
      "936/936 [==============================] - 0s 417us/step - loss: 18.6317\n",
      "Epoch 227/400\n",
      "936/936 [==============================] - 0s 424us/step - loss: 19.2439\n",
      "Epoch 228/400\n",
      "936/936 [==============================] - 0s 406us/step - loss: 19.5591\n",
      "Epoch 229/400\n",
      "936/936 [==============================] - 0s 423us/step - loss: 18.5748\n",
      "Epoch 230/400\n",
      "936/936 [==============================] - 0s 396us/step - loss: 18.6443\n",
      "Epoch 231/400\n",
      "936/936 [==============================] - 0s 412us/step - loss: 18.9410\n",
      "Epoch 232/400\n",
      "936/936 [==============================] - 0s 401us/step - loss: 18.7890\n",
      "Epoch 233/400\n",
      "936/936 [==============================] - 0s 403us/step - loss: 18.6061\n",
      "Epoch 234/400\n",
      "936/936 [==============================] - 0s 413us/step - loss: 18.5240\n",
      "Epoch 235/400\n",
      "936/936 [==============================] - 0s 414us/step - loss: 18.8497\n",
      "Epoch 236/400\n",
      "936/936 [==============================] - 0s 403us/step - loss: 18.6228\n",
      "Epoch 237/400\n",
      "936/936 [==============================] - 0s 441us/step - loss: 18.4427\n",
      "Epoch 238/400\n",
      "936/936 [==============================] - 0s 419us/step - loss: 18.8668\n",
      "Epoch 239/400\n",
      "936/936 [==============================] - 0s 391us/step - loss: 18.5543\n",
      "Epoch 240/400\n",
      "936/936 [==============================] - 0s 378us/step - loss: 18.4712\n",
      "Epoch 241/400\n",
      "936/936 [==============================] - 0s 425us/step - loss: 18.7112\n",
      "Epoch 242/400\n",
      "936/936 [==============================] - 0s 420us/step - loss: 18.5901\n",
      "Epoch 243/400\n",
      "936/936 [==============================] - 0s 405us/step - loss: 18.3480\n",
      "Epoch 244/400\n",
      "936/936 [==============================] - 0s 426us/step - loss: 18.3967\n",
      "Epoch 245/400\n",
      "936/936 [==============================] - 0s 376us/step - loss: 18.5323\n",
      "Epoch 246/400\n",
      "936/936 [==============================] - 0s 447us/step - loss: 18.6060\n",
      "Epoch 247/400\n",
      "936/936 [==============================] - 0s 416us/step - loss: 18.6555\n",
      "Epoch 248/400\n",
      "936/936 [==============================] - 0s 378us/step - loss: 18.5154\n",
      "Epoch 249/400\n",
      "936/936 [==============================] - 0s 409us/step - loss: 18.5810\n",
      "Epoch 250/400\n",
      "936/936 [==============================] - 0s 450us/step - loss: 18.3116\n",
      "Epoch 251/400\n",
      "936/936 [==============================] - 0s 405us/step - loss: 18.3291\n",
      "Epoch 252/400\n",
      "936/936 [==============================] - 0s 403us/step - loss: 18.4772\n",
      "Epoch 253/400\n",
      "936/936 [==============================] - 0s 419us/step - loss: 18.3820\n",
      "Epoch 254/400\n",
      "936/936 [==============================] - 0s 412us/step - loss: 19.0295\n",
      "Epoch 255/400\n",
      "936/936 [==============================] - 0s 425us/step - loss: 18.4492\n",
      "Epoch 256/400\n",
      "936/936 [==============================] - 0s 403us/step - loss: 18.2553\n",
      "Epoch 257/400\n",
      "936/936 [==============================] - 0s 409us/step - loss: 18.2981\n",
      "Epoch 258/400\n",
      "936/936 [==============================] - 0s 406us/step - loss: 18.3613\n",
      "Epoch 259/400\n",
      "936/936 [==============================] - 0s 388us/step - loss: 18.3785\n",
      "Epoch 260/400\n",
      "936/936 [==============================] - 0s 421us/step - loss: 18.2231\n",
      "Epoch 261/400\n",
      "936/936 [==============================] - 0s 421us/step - loss: 18.5555\n",
      "Epoch 262/400\n",
      "936/936 [==============================] - 0s 410us/step - loss: 18.3342\n",
      "Epoch 263/400\n",
      "936/936 [==============================] - 0s 475us/step - loss: 18.4222\n",
      "Epoch 264/400\n",
      "936/936 [==============================] - 0s 431us/step - loss: 18.5423\n",
      "Epoch 265/400\n",
      "936/936 [==============================] - 0s 426us/step - loss: 18.3541\n",
      "Epoch 266/400\n",
      "936/936 [==============================] - 0s 412us/step - loss: 18.2501\n",
      "Epoch 267/400\n",
      "936/936 [==============================] - 0s 510us/step - loss: 18.4018\n",
      "Epoch 268/400\n",
      "936/936 [==============================] - 0s 473us/step - loss: 18.7024\n",
      "Epoch 269/400\n",
      "936/936 [==============================] - 0s 431us/step - loss: 18.3823\n",
      "Epoch 270/400\n",
      "936/936 [==============================] - 0s 426us/step - loss: 18.1462\n",
      "Epoch 271/400\n",
      "936/936 [==============================] - 0s 429us/step - loss: 18.4933\n",
      "Epoch 272/400\n",
      "936/936 [==============================] - 0s 454us/step - loss: 18.2888\n",
      "Epoch 273/400\n",
      "936/936 [==============================] - 0s 469us/step - loss: 18.2667\n",
      "Epoch 274/400\n",
      "936/936 [==============================] - 0s 487us/step - loss: 18.2729\n",
      "Epoch 275/400\n",
      "936/936 [==============================] - 0s 509us/step - loss: 18.1983\n",
      "Epoch 276/400\n",
      "936/936 [==============================] - 1s 596us/step - loss: 18.1274\n",
      "Epoch 277/400\n",
      "936/936 [==============================] - 1s 535us/step - loss: 17.8536\n",
      "Epoch 278/400\n",
      "936/936 [==============================] - 1s 590us/step - loss: 18.1550\n",
      "Epoch 279/400\n",
      "936/936 [==============================] - 1s 966us/step - loss: 18.4454\n",
      "Epoch 280/400\n",
      "936/936 [==============================] - 1s 578us/step - loss: 18.2703\n",
      "Epoch 281/400\n",
      "936/936 [==============================] - 1s 585us/step - loss: 18.6954\n",
      "Epoch 282/400\n",
      "936/936 [==============================] - 0s 480us/step - loss: 18.3129\n",
      "Epoch 283/400\n",
      "936/936 [==============================] - 0s 462us/step - loss: 18.3709\n",
      "Epoch 284/400\n",
      "936/936 [==============================] - 0s 524us/step - loss: 18.0595\n",
      "Epoch 285/400\n",
      "936/936 [==============================] - 0s 462us/step - loss: 18.0615\n",
      "Epoch 286/400\n",
      "936/936 [==============================] - 0s 407us/step - loss: 17.9777\n",
      "Epoch 287/400\n",
      "936/936 [==============================] - 0s 446us/step - loss: 17.8648\n",
      "Epoch 288/400\n",
      "936/936 [==============================] - 0s 438us/step - loss: 17.8960\n",
      "Epoch 289/400\n",
      "936/936 [==============================] - 1s 554us/step - loss: 18.0602\n",
      "Epoch 290/400\n",
      "936/936 [==============================] - 0s 452us/step - loss: 18.1523\n",
      "Epoch 291/400\n",
      "936/936 [==============================] - 0s 400us/step - loss: 18.3168\n",
      "Epoch 292/400\n",
      "936/936 [==============================] - 0s 461us/step - loss: 18.2611\n",
      "Epoch 293/400\n",
      "936/936 [==============================] - 0s 401us/step - loss: 18.5032\n",
      "Epoch 294/400\n",
      "936/936 [==============================] - 0s 383us/step - loss: 17.9249\n",
      "Epoch 295/400\n",
      "936/936 [==============================] - 0s 431us/step - loss: 17.8484\n",
      "Epoch 296/400\n",
      "936/936 [==============================] - 0s 472us/step - loss: 18.7420\n",
      "Epoch 297/400\n",
      "936/936 [==============================] - 0s 439us/step - loss: 17.7611\n",
      "Epoch 298/400\n",
      "936/936 [==============================] - 0s 447us/step - loss: 18.0471\n",
      "Epoch 299/400\n",
      "936/936 [==============================] - 0s 421us/step - loss: 17.6862\n",
      "Epoch 300/400\n",
      "936/936 [==============================] - 0s 457us/step - loss: 17.9321\n",
      "Epoch 301/400\n",
      "936/936 [==============================] - 0s 445us/step - loss: 17.8645\n",
      "Epoch 302/400\n",
      "936/936 [==============================] - 0s 439us/step - loss: 18.3042\n",
      "Epoch 303/400\n",
      "936/936 [==============================] - 0s 442us/step - loss: 17.6372\n",
      "Epoch 304/400\n",
      "936/936 [==============================] - 0s 478us/step - loss: 17.7189\n",
      "Epoch 305/400\n",
      "936/936 [==============================] - 0s 401us/step - loss: 17.8566\n",
      "Epoch 306/400\n",
      "936/936 [==============================] - 0s 474us/step - loss: 17.9470\n",
      "Epoch 307/400\n",
      "936/936 [==============================] - 0s 434us/step - loss: 17.9104\n",
      "Epoch 308/400\n",
      "936/936 [==============================] - 0s 479us/step - loss: 17.8697\n",
      "Epoch 309/400\n",
      "936/936 [==============================] - 0s 420us/step - loss: 17.8330\n",
      "Epoch 310/400\n",
      "936/936 [==============================] - 0s 411us/step - loss: 17.9660\n",
      "Epoch 311/400\n",
      "936/936 [==============================] - 0s 411us/step - loss: 18.0640\n",
      "Epoch 312/400\n",
      "936/936 [==============================] - 0s 453us/step - loss: 17.6799\n",
      "Epoch 313/400\n",
      "936/936 [==============================] - 0s 438us/step - loss: 17.6852\n",
      "Epoch 314/400\n",
      "936/936 [==============================] - 0s 451us/step - loss: 17.6338\n",
      "Epoch 315/400\n",
      "936/936 [==============================] - 0s 426us/step - loss: 18.0156\n",
      "Epoch 316/400\n",
      "936/936 [==============================] - 0s 468us/step - loss: 17.9908\n",
      "Epoch 317/400\n",
      "936/936 [==============================] - 0s 444us/step - loss: 17.4616\n",
      "Epoch 318/400\n",
      "936/936 [==============================] - 0s 428us/step - loss: 17.6530\n",
      "Epoch 319/400\n",
      "936/936 [==============================] - 0s 437us/step - loss: 17.8829\n",
      "Epoch 320/400\n",
      "936/936 [==============================] - 0s 427us/step - loss: 17.5388\n",
      "Epoch 321/400\n",
      "936/936 [==============================] - 0s 436us/step - loss: 17.6140\n",
      "Epoch 322/400\n",
      "936/936 [==============================] - 0s 498us/step - loss: 17.41080s - loss: 1\n",
      "Epoch 323/400\n",
      "936/936 [==============================] - 0s 416us/step - loss: 17.3862\n",
      "Epoch 324/400\n",
      "936/936 [==============================] - 0s 427us/step - loss: 17.7739\n",
      "Epoch 325/400\n",
      "936/936 [==============================] - 0s 424us/step - loss: 17.4055\n",
      "Epoch 326/400\n",
      "936/936 [==============================] - 0s 446us/step - loss: 17.6175\n",
      "Epoch 327/400\n",
      "936/936 [==============================] - 0s 448us/step - loss: 17.8700\n",
      "Epoch 328/400\n",
      "936/936 [==============================] - 0s 435us/step - loss: 18.0634\n",
      "Epoch 329/400\n",
      "936/936 [==============================] - 0s 483us/step - loss: 17.6949\n",
      "Epoch 330/400\n",
      "936/936 [==============================] - 0s 473us/step - loss: 17.56360s -\n",
      "Epoch 331/400\n",
      "936/936 [==============================] - 1s 569us/step - loss: 17.5814\n",
      "Epoch 332/400\n",
      "936/936 [==============================] - 1s 709us/step - loss: 17.7565\n",
      "Epoch 333/400\n",
      "936/936 [==============================] - 0s 483us/step - loss: 17.8506\n",
      "Epoch 334/400\n",
      "936/936 [==============================] - 0s 416us/step - loss: 17.7235\n",
      "Epoch 335/400\n",
      "936/936 [==============================] - 0s 473us/step - loss: 17.6335\n",
      "Epoch 336/400\n",
      "936/936 [==============================] - 0s 463us/step - loss: 18.3298\n",
      "Epoch 337/400\n",
      "936/936 [==============================] - 0s 467us/step - loss: 17.7410\n",
      "Epoch 338/400\n",
      "936/936 [==============================] - 0s 424us/step - loss: 17.3098\n",
      "Epoch 339/400\n",
      "936/936 [==============================] - 0s 447us/step - loss: 17.2739\n",
      "Epoch 340/400\n",
      "936/936 [==============================] - 0s 450us/step - loss: 17.3654\n",
      "Epoch 341/400\n",
      "936/936 [==============================] - 0s 434us/step - loss: 17.4822\n",
      "Epoch 342/400\n",
      "936/936 [==============================] - 0s 450us/step - loss: 17.6819\n",
      "Epoch 343/400\n",
      "936/936 [==============================] - 0s 479us/step - loss: 17.5882\n",
      "Epoch 344/400\n",
      "936/936 [==============================] - 0s 444us/step - loss: 17.4068\n",
      "Epoch 345/400\n",
      "936/936 [==============================] - 0s 500us/step - loss: 17.9126\n",
      "Epoch 346/400\n",
      "936/936 [==============================] - 0s 525us/step - loss: 17.3734\n",
      "Epoch 347/400\n",
      "936/936 [==============================] - 0s 448us/step - loss: 17.4202\n",
      "Epoch 348/400\n",
      "936/936 [==============================] - 0s 436us/step - loss: 17.4454\n",
      "Epoch 349/400\n",
      "936/936 [==============================] - 0s 456us/step - loss: 17.6981\n",
      "Epoch 350/400\n",
      "936/936 [==============================] - 0s 464us/step - loss: 17.6031\n",
      "Epoch 351/400\n",
      "936/936 [==============================] - 0s 463us/step - loss: 17.2567\n",
      "Epoch 352/400\n",
      "936/936 [==============================] - 0s 446us/step - loss: 17.5475\n",
      "Epoch 353/400\n",
      "936/936 [==============================] - 0s 484us/step - loss: 17.3643\n",
      "Epoch 354/400\n",
      "936/936 [==============================] - 0s 474us/step - loss: 17.6148\n",
      "Epoch 355/400\n",
      "936/936 [==============================] - 0s 450us/step - loss: 17.4004\n",
      "Epoch 356/400\n",
      "936/936 [==============================] - 0s 464us/step - loss: 17.2250\n",
      "Epoch 357/400\n",
      "936/936 [==============================] - 0s 442us/step - loss: 17.3769\n",
      "Epoch 358/400\n",
      "936/936 [==============================] - 0s 445us/step - loss: 17.5815\n",
      "Epoch 359/400\n",
      "936/936 [==============================] - 0s 473us/step - loss: 17.3121\n",
      "Epoch 360/400\n",
      "936/936 [==============================] - 0s 457us/step - loss: 17.1224\n",
      "Epoch 361/400\n",
      "936/936 [==============================] - 0s 442us/step - loss: 17.3338\n",
      "Epoch 362/400\n",
      "936/936 [==============================] - 0s 511us/step - loss: 17.1724\n",
      "Epoch 363/400\n",
      "936/936 [==============================] - 0s 497us/step - loss: 17.1783\n",
      "Epoch 364/400\n",
      "936/936 [==============================] - 0s 437us/step - loss: 17.9787\n",
      "Epoch 365/400\n",
      "936/936 [==============================] - 0s 525us/step - loss: 18.1491\n",
      "Epoch 366/400\n",
      "936/936 [==============================] - 0s 508us/step - loss: 17.4831\n",
      "Epoch 367/400\n",
      "936/936 [==============================] - 0s 513us/step - loss: 17.9563\n",
      "Epoch 368/400\n",
      "936/936 [==============================] - 0s 441us/step - loss: 18.5038\n",
      "Epoch 369/400\n",
      "936/936 [==============================] - 0s 486us/step - loss: 17.4264\n",
      "Epoch 370/400\n",
      "936/936 [==============================] - 0s 467us/step - loss: 17.3761\n",
      "Epoch 371/400\n",
      "936/936 [==============================] - 0s 413us/step - loss: 17.3413\n",
      "Epoch 372/400\n",
      "936/936 [==============================] - 0s 426us/step - loss: 17.2854\n",
      "Epoch 373/400\n",
      "936/936 [==============================] - 0s 508us/step - loss: 17.1649\n",
      "Epoch 374/400\n",
      "936/936 [==============================] - 0s 476us/step - loss: 17.7476\n",
      "Epoch 375/400\n",
      "936/936 [==============================] - 0s 475us/step - loss: 18.1830\n",
      "Epoch 376/400\n",
      "936/936 [==============================] - 0s 469us/step - loss: 17.5785\n",
      "Epoch 377/400\n",
      "936/936 [==============================] - 0s 511us/step - loss: 17.3187\n",
      "Epoch 378/400\n",
      "936/936 [==============================] - 0s 464us/step - loss: 17.2365\n",
      "Epoch 379/400\n",
      "936/936 [==============================] - 0s 487us/step - loss: 17.3409\n",
      "Epoch 380/400\n",
      "936/936 [==============================] - 0s 468us/step - loss: 17.4679\n",
      "Epoch 381/400\n",
      "936/936 [==============================] - 0s 456us/step - loss: 17.3728\n",
      "Epoch 382/400\n",
      "936/936 [==============================] - 0s 423us/step - loss: 17.1511\n",
      "Epoch 383/400\n",
      "936/936 [==============================] - 0s 478us/step - loss: 17.2208\n",
      "Epoch 384/400\n",
      "936/936 [==============================] - 1s 573us/step - loss: 17.8397\n",
      "Epoch 385/400\n",
      "936/936 [==============================] - 0s 478us/step - loss: 18.0975\n",
      "Epoch 386/400\n",
      "936/936 [==============================] - 0s 437us/step - loss: 17.1393\n",
      "Epoch 387/400\n",
      "936/936 [==============================] - 0s 485us/step - loss: 17.3028\n",
      "Epoch 388/400\n",
      "936/936 [==============================] - 1s 561us/step - loss: 17.3701\n",
      "Epoch 389/400\n",
      "936/936 [==============================] - 0s 463us/step - loss: 17.2878\n",
      "Epoch 390/400\n",
      "936/936 [==============================] - 0s 505us/step - loss: 17.1167\n",
      "Epoch 391/400\n",
      "936/936 [==============================] - 0s 494us/step - loss: 17.0736\n",
      "Epoch 392/400\n",
      "936/936 [==============================] - 0s 487us/step - loss: 18.7131\n",
      "Epoch 393/400\n",
      "936/936 [==============================] - 0s 462us/step - loss: 17.3070\n",
      "Epoch 394/400\n",
      "936/936 [==============================] - 0s 476us/step - loss: 17.1722\n",
      "Epoch 395/400\n",
      "936/936 [==============================] - 0s 489us/step - loss: 17.2572\n",
      "Epoch 396/400\n",
      "936/936 [==============================] - 1s 549us/step - loss: 17.4078\n",
      "Epoch 397/400\n",
      "936/936 [==============================] - 0s 494us/step - loss: 17.0049\n",
      "Epoch 398/400\n",
      "936/936 [==============================] - 0s 486us/step - loss: 17.0537\n",
      "Epoch 399/400\n",
      "936/936 [==============================] - 0s 510us/step - loss: 17.2056\n",
      "Epoch 400/400\n",
      "936/936 [==============================] - 0s 487us/step - loss: 17.0820\n",
      "Wall time: 3min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1fea7745ac8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_1s_sj.fit(train_1s_sj, data_y_1s_sj, epochs=400, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1s_iq = Sequential()\n",
    "model_1s_iq.add(Bidirectional(LSTM(50, activation='relu', return_sequences=True, input_shape=(1, 23))))\n",
    "model_1s_iq.add(Bidirectional(LSTM(40, activation='relu', return_sequences=True)))\n",
    "model_1s_iq.add(Bidirectional(LSTM(20, activation='relu')))\n",
    "model_1s_iq.add(Dense(1))\n",
    "model_1s_iq.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1feef28c780>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_1s_iq.fit(train_1s_iq, data_y_1s_iq, epochs=400, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 1, 23)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1s_test_sj = X_test_sj_scaled.reshape(X_test_sj_scaled.shape[0],1,X_test_sj_scaled.shape[1])\n",
    "data_1s_test_iq = X_test_iq_scaled.reshape(X_test_iq_scaled.shape[0],1,X_test_iq_scaled.shape[1])\n",
    "data_1s_test_sj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sj = model_1s_sj.predict(data_1s_test_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_iq = model_1s_iq.predict(data_1s_test_iq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city  year  weekofyear  total_cases\n",
       "0   sj  2008          18           30\n",
       "1   sj  2008          19           11\n",
       "2   sj  2008          20           14\n",
       "3   sj  2008          21           15\n",
       "4   sj  2008          22           11"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_predict = pd.read_csv('data_dengue/dengue_features_test.csv', index_col=None)\n",
    "result_columns_sj = X_test[X_test.city=='sj'][['city','year','weekofyear']]\n",
    "result_cases_sj = pd.DataFrame(predict_sj)\n",
    "result_cases_sj.columns = ['total_cases']\n",
    "result_df_sj = pd.concat([result_columns_sj, result_cases_sj], axis=1)\n",
    "result_df_sj['total_cases'] = result_df_sj['total_cases'].round().astype(int)\n",
    "result_df_sj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>iq</td>\n",
       "      <td>2010</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>iq</td>\n",
       "      <td>2010</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>iq</td>\n",
       "      <td>2010</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>iq</td>\n",
       "      <td>2010</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>iq</td>\n",
       "      <td>2010</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city  year  weekofyear  total_cases\n",
       "0   iq  2010          26            2\n",
       "1   iq  2010          27            1\n",
       "2   iq  2010          28            5\n",
       "3   iq  2010          29            0\n",
       "4   iq  2010          30            3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_columns_iq = X_test[X_test.city=='iq'][['city','year','weekofyear']]\n",
    "result_cases_iq = pd.DataFrame(predict_iq)\n",
    "result_cases_iq.columns = ['total_cases']\n",
    "result_columns_iq = result_columns_iq.reset_index()\n",
    "result_df_iq = pd.concat([result_columns_iq, result_cases_iq], axis=1)\n",
    "result_df_iq['total_cases'] = result_df_iq['total_cases'].round().astype(int)\n",
    "result_df_iq = result_df_iq.drop(['index'], axis=1)\n",
    "result_df_iq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>total_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>sj</td>\n",
       "      <td>2008</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city  year  weekofyear  total_cases\n",
       "0   sj  2008          18           30\n",
       "1   sj  2008          19           11\n",
       "2   sj  2008          20           14\n",
       "3   sj  2008          21           15\n",
       "4   sj  2008          22           11"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.concat([result_df_sj,result_df_iq], axis=0)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('lstm_2_city_BI_50_40_30.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
